import numpy as np
import pandas as pd

def verify_proton_decay_suppression():
    """
    Verification of Topological vs. Perturbative Proton Decay Suppression
    
    Standard minimal SU(5) GUTs predict τ_p ~ 10^{31}–10^{32} years (ruled out).
    This calculation quantifies the shortfall and demonstrates the requirement
    for additional non-perturbative (topological) suppression.
    """
    print("═" * 78)
    print("PROTON DECAY: PERTURBATIVE EFT vs. EXPERIMENTAL BOUNDS")
    print("Quantifying the Shortfall in Minimal SU(5) Predictions")
    print("═" * 78)

    # Physical constants and benchmarks
    alpha_gut = 1 / 42.0                  # Typical GUT coupling
    m_p_gev = 0.938                       # Proton mass
    M_X_base_gev = 1e15                   # Nominal unification scale
    hbar_gev_s = 6.582e-25                # ħ in GeV·s
    sec_per_year = 3.156e7                # Seconds per year

    exp_bound_years = 2.4e34              # Super-Kamiokande lower bound (p → e⁺ π⁰)
    lit_su5_years = 1e32                  # Typical minimal SU(5) prediction

    # Base perturbative calculation (dimension-6 operator)
    alpha_sq = alpha_gut ** 2
    m_p5 = m_p_gev ** 5
    Gamma_base = alpha_sq * m_p5 / M_X_base_gev**4
    tau_base_years = hbar_gev_s / Gamma_base / sec_per_year

    shortfall_exp = exp_bound_years / tau_base_years
    shortfall_lit = lit_su5_years / tau_base_years

    print(f"\nBase Parameters:")
    print(f"  α_GUT   ≈ {alpha_gut:.4f}")
    print(f"  M_X     = {M_X_base_gev:.1e} GeV")
    print(f"  m_p     = {m_p_gev:.3f} GeV")
    print("-" * 50)
    print(f"Perturbative Prediction (Nominal):")
    print(f"  τ_p     ≈ {tau_base_years:.2e} years")
    print(f"  Literature SU(5) ≈ {lit_su5_years:.2e} years")
    print(f"  Experimental     > {exp_bound_years:.2e} years")
    print("-" * 50)
    print(f"Shortfall Factors:")
    print(f"  vs. Experiment : ×{shortfall_exp:.0f}")
    print(f"  vs. Literature : ×{shortfall_lit:.1f}")
    print("-" * 50)

    # Monte Carlo variation
    n_mc = 1000
    np.random.seed(42)

    # Log-uniform M_X around nominal (factor ~40 variation)
    M_X_samples = np.logspace(np.log10(5e14), np.log10(2e16), n_mc)
    # Uniform α_GUT variation ±10%
    alpha_samples = alpha_gut * np.random.uniform(0.9, 1.1, n_mc)

    tau_mc_years = []
    for i in range(n_mc):
        alpha_sq_i = alpha_samples[i]**2
        Gamma_i = alpha_sq_i * m_p5 / M_X_samples[i]**4
        tau_i = hbar_gev_s / Gamma_i / sec_per_year
        tau_mc_years.append(tau_i)

    tau_mc = np.array(tau_mc_years)
    log_tau = np.log10(tau_mc)

    mean_tau = np.mean(tau_mc)
    median_tau = np.median(tau_mc)
    std_tau = np.std(tau_mc)
    p_above_exp = np.mean(tau_mc > exp_bound_years) * 100
    p_above_lit = np.mean(tau_mc > lit_su5_years) * 100

    print(f"\nMonte Carlo Results ({n_mc} samples):")
    print(f"  Mean τ_p     = {mean_tau:.2e} years")
    print(f"  Median τ_p   = {median_tau:.2e} years")
    print(f"  Std dev      = {std_tau:.2e} years")
    print(f"  P(τ_p > exp) = {p_above_exp:.1f}%")
    print(f"  P(τ_p > lit) = {p_above_lit:.1f}%")
    print("-" * 50)

    # Binned distribution as clean table (no ASCII bars)
    bins = 10
    hist, bin_edges = np.histogram(log_tau, bins=bins)
    bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2

    print("Distribution of log₁₀(τ_p [years]):")
    dist_data = []
    for center, count in zip(bin_centers, hist):
        percentage = (count / n_mc) * 100
        dist_data.append({
            "log₁₀(τ_p)": f"{center:.2f}",
            "Count": count,
            "Percentage": f"{percentage:.1f}%"
        })

    df_dist = pd.DataFrame(dist_data)
    print(df_dist.to_string(index=False))

if __name__ == "__main__":
    verify_proton_decay_suppression()