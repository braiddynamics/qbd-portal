---
title: "Search for the Primitive c. 1900–1950"
sidebar_label: "c. 1900–1950"
---

---

### The Geometric Invasion: The Reluctant Revolution

The narrative of the “First Revolution” is often simplified into a story of solitary genius, with Albert Einstein as the sole architect of the modern worldview. However, a granular historical analysis reveals that the transition from a Newtonian absolute stage to a relativistic spacetime was a dialectical process, fraught with resistance, interdisciplinary conflict, and a profound struggle between physical intuition and mathematical formalism. The birth of spacetime was a decade-long negotiation between the physicist’s desire for tangible mechanism and the mathematician’s drive for axiomatic purity.

:::info[**Minkowski’s Declaration**]
:::

While Albert Einstein provided the physical insights of Special Relativity in his Annus Mirabilis of 1905, dismantling the concept of absolute simultaneity, he did not immediately discard the separateness of space and time. His 1905 formulation relied on kinematic arguments involving rigid rods and synchronized clocks, tangible, operational definitions rooted in the positivist tradition of Ernst Mach. It was his former mathematics professor at the Zurich Polytechnic, Hermann Minkowski, who in 1908 recognized the deeper geometric imperative hidden within Einstein’s algebra.

Minkowski’s intervention was decisive and, to Einstein, initially unwelcome. In a now-legendary address to the 80th Assembly of German Natural Scientists and Physicians in Cologne, Minkowski delivered the death knell of the distinct categories of space and time. His words were messianic in tone, signaling a total ontological shift: “Henceforth space by itself, and time by itself, are doomed to fade away into mere shadows, and only a kind of union of the two will preserve an independent reality.”

Minkowski’s contribution: a “world” in which events are points defined by four coordinates

$$
x, y, z, t
$$

Crucially, Minkowski introduced the invariant interval, a geometric measure that remains constant for all observers regardless of their relative motion. This was the “geometric soul” of relativity, replacing the relative measurements of space and time with an absolute metric of spacetime.

However, the reception of this idea by the physicist who sparked it was initially hostile. Einstein, driven by a physicist’s suspicion of abstract formalism that lacked immediate empirical referents, viewed Minkowski’s four-dimensional formalism as “superfluous learnedness” (überflüssige Gelehrsamkeit). He famously remarked to a colleague, “Since the mathematicians have invaded the relativity theory, I do not understand it myself any more.” Einstein felt that the mathematization of his physical theory obscured the underlying reality of the forces and kinematics he had so carefully constructed.

This resistance highlights a critical epistemological divide that defined the early 20th century: the tension between constructive theories (built on physical mechanisms) and principle theories (built on mathematical axioms). Einstein initially feared that the high-level geometry obscured the physical reality. Yet, the “invasion” proved decisive. By 1912, as Einstein struggled to generalize his theory to include gravity, he realized that the rigid Euclidean geometry of his earlier thought was insufficient. Gravity could not be described by a scalar field in a flat background; it required a dynamic, curved metric. He was forced to adopt the very mathematical machinery he had mocked, eventually conceding that Minkowski’s “arrogant” mathematics was the only path to General Relativity. In a letter to Arnold Sommerfeld, Einstein admitted his conversion, noting that he had “gained a great respect for mathematics, whose more subtle parts I considered until now, in my ignorance, as pure luxury.”

:::info[**The Race for the Field Equations: Einstein vs. Hilbert**]
:::

The culmination of the geometric revolution occurred in the fevered month of November 1915, a period that illustrates the convergence of the physicist’s intuition and the mathematician’s axiomatic rigor. As Einstein labored to define how matter curves spacetime, the great mathematician David Hilbert, pursuing his own “Sixth Problem” to axiomatize all of physics, entered the fray.

Hilbert’s ambition was grander than merely solving the problem of gravity. In his 1900 address to the International Congress of Mathematicians, he had outlined 23 problems for the coming century. The Sixth Problem was explicit: “To treat in the same manner, by means of axioms, those physical sciences in which mathematics plays an important part.” Hilbert believed reality could be reduced to a finite set of logical primitives and derivation rules, a “Theory of Everything” rooted in pure logic. By 1915, he saw Einstein’s work on gravity as the perfect candidate for this axiomatization.

In the autumn of 1915, Einstein and Hilbert engaged in an intense correspondence and competition. Einstein had visited Göttingen in the summer to lecture on his developing theory, and Hilbert was fascinated. By November, both men were racing to find the correct field equations. Hilbert, working from a variational principle (the Einstein-Hilbert action), derived the field equations almost simultaneously with Einstein.

The historical record reflects a moment of high tension. Einstein, exhausted and fearing that Hilbert would “appropriate” his work, accelerated his efforts. On November 18, Einstein discovered that his previous equations were flawed (they did not predict the correct perihelion precession of Mercury). Hilbert, meanwhile, submitted a paper on November 20, 1915, titled Die Grundlagen der Physik (“The Foundations of Physics”), which contained the correct variational derivation of the equations. Einstein, pushing himself to the brink of physical collapse, presented the correct field equations to the Prussian Academy five days later, on November 25, 1915.

While a priority dispute simmered among historians for decades, recent analysis of Hilbert’s printer proofs reveals that while he submitted the paper on the 20th, the explicit form of the field equations was likely inserted into the proofs after seeing Einstein’s paper. Regardless of the minutiae of dates, the personal resolution between the two giants was amicable. Hilbert openly admitted that while his mathematics produced the equation, the physical insight belonged entirely to Einstein. He famously quipped that “Every boy in the streets of Göttingen understands more about four-dimensional geometry than Einstein. Yet, in spite of that, Einstein did the work and not the mathematicians.”

This period established the Geometric Paradigm: the universe was a dynamic continuum, a smooth manifold where gravity was the curvature of the stage itself. For the next half-century, “Geometry was Destiny.” Matter (the “It”) told spacetime (the “Stage”) how to curve, and spacetime told matter how to move. The separation between the container and the contained had been dissolved into a single interacting entity, fulfilling Minkowski’s prophecy.

---

### Dissolution of Substance: Trajectories to Quantum Information

In the three decades between 1925 and 1957, the ontological foundation of physics underwent a total disintegration. The resulting conceptual vacuum remains unfilled. For nearly three centuries prior, the fundamental constituent of reality in physics had been conceived as a substance located in space and time, possessing determinate properties independent of observation. A particle was a particle; it had a position ($x$) and a momentum ($p$), and these variables traced a smooth, continuous trajectory through the cosmos.

:::info[**The Iconoclasts: Heisenberg, Matrix Mechanics, and the End of the Orbit**]
:::

The first casualty of the quantum revolution was the concept of the planetary orbit. By the early 1920s, the “Old Quantum Theory,” a patchwork of classical mechanics and ad-hoc quantization rules developed by Niels Bohr and Arnold Sommerfeld, was collapsing under its own inconsistencies. While it could describe the hydrogen spectrum, it failed miserably for helium and could not account for the anomalous Zeeman effect. More alarmingly, it presumed that electrons moved in defined elliptical orbits, yet these orbits were physically unobservable.

In the summer of 1925, fleeing a severe bout of hay fever, the 23-year-old Werner Heisenberg retreated to the stark, treeless island of Helgoland in the North Sea. Isolated and feverish, he made a decision that would sever the link between physics and visual intuition. He decided to discard the unobservable. In classical kinematics, the motion of a particle is described by a function $x(t)$, a continuous line in space. Heisenberg realized that in the atomic domain, we never observe $x(t)$. We observe only the frequencies and intensities of the light emitted during transitions between energy levels. He reasoned that if the electron’s orbit cannot be observed, it should not be part of the theory. This was a radical positivistic move: the theory should contain only quantities that are, in principle, measurable.

In a letter to Wolfgang Pauli dated July 9, 1925, Heisenberg wrote of his “pitiful efforts” to kill off the concept of orbits entirely. He replaced the classical Fourier series, which described the continuous motion of a planet or a vibrating string, with a new calculus. In classical theory, a periodic motion is decomposed into frequencies that are integer multiples of a fundamental frequency. Heisenberg found that in the atom, the frequencies were differences between energy terms, in line with the Rydberg-Ritz combination principle.

Heisenberg’s “Umdeutung” (reinterpretation) paper of 1925 proposed a mechanics based solely on these transition quantities. Instead of a single number representing position, he arranged quantities in square arrays, though he did not yet know the term “matrix,” where the element $X_{nm}$ represented the transition amplitude between state $n$ and state $m$. When he multiplied these arrays to calculate physical quantities like energy, he discovered a shocking property: the order of multiplication mattered. In classical arithmetic, $3 \times 4$ equals $4 \times 3$. In Heisenberg’s new mechanics, the position array $X$ and the momentum array $P$ did not commute: $XP - PX \neq 0$.

Upon returning to Göttingen, Heisenberg handed his paper to his mentor Max Born. Born, recognizing the mathematics from his student days, realized Heisenberg had reinvented matrix algebra. Together with Pascual Jordan, they formalized the theory, famously deriving the canonical commutation relation:

$$
XP - PX = \frac{ih}{2\pi}
$$

This mathematical non-commutativity was the tombstone of the classical trajectory. If $X$ and $P$ do not commute, they cannot simultaneously possess precise numerical values. The “It” could no longer be a point moving along a line, because “position” and “momentum” were no longer simultaneously definable attributes of reality. They were operators acting on a state, not properties of the state itself.

The reception was mixed. The theory was incredibly successful at predicting spectra, but it was, as Schrödinger later described, “of repelling abstractness.” It offered no picture of what the electron was doing. It reduced the atom to a spreadsheet of transition probabilities, a black box that took inputs and gave outputs but contained no internal machinery. This was the first step toward “It from Bit”: the dissolution of the object into a table of data.

Two years later, Heisenberg cemented the physical meaning of his non-commutative algebra with the Uncertainty Principle. In a 1927 paper, he analyzed the operational limits of measurement, such as using a gamma-ray microscope to locate an electron. He argued that the very act of observation, bouncing a photon off a particle, disturbs the particle. However, Heisenberg’s interpretation evolved. Initially, he viewed the uncertainty as a result of a mechanical disturbance, a clumsy observer bumping into the delicate furniture of the quantum world. But as the Copenhagen interpretation matured, the view shifted. Uncertainty was not a result of imperfect measurement; it was a fundamental property of the “It” itself. An electron simply does not possess a simultaneous position and momentum. The “It” was no longer a solid object; it was a “tendency” to exist, what Heisenberg later referred to, borrowing from Aristotle, as potentia, something standing midway between the idea of an event and the actual event.

---

### The Wave and the Web: Erwin Schrödinger

If Heisenberg was the executioner of the classical trajectory, Erwin Schrödinger was the counter-revolutionary who inadvertently deepened the crisis. In 1926, disgusted by the “transcendental algebra” of the Göttingen school, Schrödinger sought to restore visualizability and continuity to physics.

Drawing on Louis de Broglie’s 1924 hypothesis of matter waves, Schrödinger formulated the wave equation

$$
H\psi = E\psi
$$

Unlike Heisenberg’s discrete matrices, Schrödinger’s $\psi$ was a continuous field evolving smoothly in time. For a brief moment, it seemed the classical “It” was saved; particles were simply wave packets, localized lumps of field density moving through space. The physics community embraced Wave Mechanics with relief. It used the familiar tools of partial differential equations, the “crowning glory of traditional physics.” It felt like classical electromagnetism. However, this hope was a mirage. Schrödinger soon realized that the wave function for two particles did not exist in 3-dimensional physical space, but in a 6-dimensional configuration space. For $N$ particles, the wave function lived in $3N$ dimensions. This was not a physical wave in the ether; it was a wave of information in an abstract mathematical manifold.

Furthermore, wave packets inevitably spread over time. A particle localized as a “hump” would eventually dissipate across the universe. Schrödinger’s attempt to interpret $\psi$ as a physical charge density collapsed when it became clear that the wave packet did not stay together. The “It” could not be a wave of matter.

The interpretation that would seal the fate of the “It” came from Max Born in 1926. Analyzing the scattering of particles using Schrödinger’s formalism, Born proposed that the square of the wave amplitude ($|\psi|^2$) did not represent a physical density of charge, but a probability density. In a famous paper on collision theory, Born added a footnote that marked the moment physics abandoned the prediction of individual events. “The motion of particles follows probability laws,” Born asserted, but the probability itself propagates according to strict causality. This created a bifurcation in the nature of the “It” that persists to this day:

- The Wavefunction ($\psi$): Deterministic, continuous, strictly causal, but unobservable and abstract.
- The Measurement Result: Discrete, real, but probabilistic and acausal.

Schrödinger was horrified. He had hoped to eliminate the quantum jumps; instead, his equation became the vehicle for formalizing them. The “It” was no longer a substance; it was a betting slip.

:::info[**The Copenhagen Synthesis: Bohr, Complementarity, and the Cut**]
:::

While Heisenberg provided the mathematics of uncertainty and Born the statistical interpretation, Niels Bohr provided the philosophy that made the destruction of realism palatable. Operating from his institute in Copenhagen, Bohr dismantled the classical separation between the observer and the observed, effectively redefining what it means to be an “It.”

In classical physics, a measurement is a passive gaze; the “It” exists “out there,” and the observer merely records its pre-existing properties. Bohr argued that in the quantum realm, the interaction between the measuring instrument and the atomic object is finite, governed by the quantum of action ($h$), and uncontrollable. This interaction creates an “indivisible whole” which Bohr termed a phenomenon. One cannot speak of the electron’s behavior independent of the measuring device. The “electron” is an abstraction; the reality is the “electron-plus-Geiger-counter-clicking” event. In Bohr’s view, “No elementary phenomenon is a phenomenon until it is a registered (observed) phenomenon,” a phrase later popularized by Wheeler.

Unveiled at the Como Conference in 1927, Bohr’s doctrine of Complementarity asserted that the “It” has no intrinsic properties in isolation. An electron is not a wave; nor is it a particle. It behaves as a wave in the context of a diffraction grating and as a particle in the context of a collision experiment. These descriptions are mutually exclusive but jointly necessary for a complete description of experience. Bohr drew analogies to psychology, noting the difficulty of separating the subject from the object in introspection. Just as we cannot observe our own anger without altering it, we cannot observe an atom without participating in its definition.

Crucially, Bohr insisted that the “It” of the measuring device must be described in classical language. We must communicate our results unambiguously using heavy, macroscopic concepts (pointers, scales, clocks). This created a conceptual boundary, the Heisenberg Cut, between the quantum system (probabilistic, indefinable, described by $\psi$) and the classical observer (deterministic, communicable, described by Newton/Maxwell). This was Bohr’s pragmatic solution to the crisis: the “It” had died in the microcosm, but it was resurrected as a necessary fiction in the macrocosm to allow scientists to speak to one another. The price was a fractured worldview where the laws of physics changed depending on the size of the object.

:::info[**The Clash of Completeness: The Bohr-Einstein Debates**]
:::

The death of the classical “It” did not happen without a ferocious defense. Albert Einstein served as the attorney for an objective, independent reality, believing that “God does not play dice.” The debates between Einstein and Bohr are legendary not just for their intellectual height but for how they refined the definition of information in physics.

At the Fifth Solvay Conference in 1927, Einstein proposed thought experiments designed to prove that quantum mechanics was inconsistent, that one could measure position and momentum simultaneously better than Heisenberg allowed. He suggested a single-slit experiment where one measures the recoil of the screen to determine the momentum of the particle passing through. Bohr refuted this by applying the uncertainty principle to the screen itself: if you know the screen’s momentum precisely (to measure recoil), its position becomes uncertain, washing out the interference pattern.

In 1930, at the Sixth Solvay Conference, Einstein brought a more formidable weapon: the Photon Box. He imagined a box filled with radiation, with a shutter controlled by a clock. The shutter opens for a brief time $\Delta t$, releasing a single photon. By weighing the box before and after (measuring mass change $\Delta m$), one could determine the energy of the photon ($E=mc^2$) to arbitrary precision. Thus, one would know both the precise time of emission ($\Delta t$) and the precise energy ($\Delta E$), violating the Heisenberg uncertainty relation $\Delta E \Delta t \geq h$. Bohr was reportedly shocked, wandering the conference looking “like a somnambulist.” But after a sleepless night, he returned with a counter-stroke using Einstein’s own General Relativity. Bohr argued that the weighing of the box requires it to move in a gravitational field (e.g., on a spring scale). The uncertainty in the box’s position (necessary for the weighing) induces an uncertainty in the rate of the clock due to gravitational time dilation. The calculation perfectly recovered the uncertainty principle. Einstein was defeated on consistency, but he would not yield on ontology.

In 1935, Einstein, Boris Podolsky, and Nathan Rosen (EPR) changed the angle of attack. They published “Can Quantum-Mechanical Description of Physical Reality Be Considered Complete?”, a paper that remains one of the most cited in the history of physics. They established a “Criterion of Reality”: “If, without in any way disturbing a system, we can predict with certainty... the value of a physical quantity, then there exists an element of physical reality corresponding to this physical quantity.”

EPR imagined two particles ($A$ and $B$) that interact and then fly apart. Due to conservation laws, their positions and momenta are perfectly correlated

$$
x_A - x_B = x_0 , p_A + p_B = 0
$$

If we measure the position of $A$, we instantly know the position of $B$. If we measure the momentum of $A$, we instantly know the momentum of $B$. Since $A$ and $B$ are spacelike separated, our choice of measurement on $A$ cannot physically disturb $B$ (assuming Locality). Therefore, $B$ must have had both a definite position and a definite momentum all along. Since quantum mechanics says B cannot have both, the theory is incomplete.

Bohr’s response, published under the same title, was a “bolt from the blue.” He essentially rejected the separation of $A$ and $B$. He argued that “the whole arrangement,” the source, the particles, and the distant detectors, constitutes a single, unanalyzable phenomenon. There is no “It” at location $B$ independent of the setting at location $A$. Bohr redefined “physical reality” to include the context of the measurement. This was the capitulation of local realism. The “It” was now non-local, spread across the entire experimental context. The “cut” between observer and observed now extended across light-years.

:::info[**The Paradox of Entanglement: Schrödinger’s Cat and the Holism of Information**]
:::

Schrödinger, observing the EPR debate from Oxford, was inspired to identify the singular feature of quantum mechanics that defied classical ontology. In a 1935 paper, he coined the term Entanglement (German: Verschränkung). Schrödinger realized that when two systems interact and then separate, they can no longer be described by independent wave functions ($\psi_A$ and $\psi_B$). They possess only a single, joint wave function ($\psi_{AB}$). The “It” (the individual particle) ceases to exist mathematically; only the “System” exists.

Schrödinger wrote: “Maximal knowledge of a total system does not necessarily include total knowledge of all its parts, not even when these are completely separated... and do not influence each other at present.” Information is stored not in the particles, but in the correlations between them. He also introduced the concept of steering: by measuring particle $A$, the experimenter can “steer” particle $B$ into a specific state (eigenstate of position or momentum) without touching it. This anticipation of quantum teleportation highlighted that information in the quantum world is non-local and shared.

To demonstrate the absurdity of the prevailing “blurred” reality accepted by the Copenhagenists, Schrödinger devised his famous Cat thought experiment. He imagined a macroscopic system (a cat) entangled with a microscopic one (a radioactive atom). According to the formalism, if the atom is in a superposition of “decayed” and “not decayed,” and the decay triggers a mechanism to kill the cat, then the cat must be in a superposition of “dead” and “alive” prior to observation. Schrödinger intended this as a reductio ad absurdum. He believed the “It” of a cat must be either dead or alive, regardless of observation. He wanted to show that the “smearing” of reality (superposition) shouldn’t apply to everyday objects. Ironically, history inverted his intent. We now understand that the cat is in a superposition (until decoherence sets in). Schrödinger inadvertently laid the groundwork for the “Many Worlds” interpretation and modern decoherence theory. He showed that the “smearing” of reality could not be confined to the atom; it infected the observer’s world as well.

---

### The Thermodynamic Link: Leo Szilard and the Birth of the Bit

While Bohr and Einstein debated metaphysics, a Hungarian physicist, Leo Szilard, was quietly forging the physical link between the abstract “bit” and the concrete “atom.” His work provided the “missing link” explaining why observation is an active physical process.

In 1929, Szilard published “On the Decrease of Entropy in a Thermodynamic System by the Intervention of Intelligent Beings.” He addressed the paradox of Maxwell’s Demon, a hypothetical being who controls a door between two gas chambers, sorting fast molecules from slow ones to create a temperature difference, thereby violating the Second Law of Thermodynamics. Szilard realized that for the Demon to sort the molecules, it must first measure them. It must acquire information about their position and velocity. Szilard analyzed a simplified “one-molecule engine.” He showed that the Demon must:

1. Measure the particle (Left or Right).
2. Store this result in a memory.
3. Actuate a piston based on this memory to extract work.

Szilard postulated that the act of measurement (or the subsequent erasure of that memory to reset the cycle) carries an entropy cost. He derived that the acquisition of one bit of information (distinguishing between two possibilities) corresponds to an entropy increase of:

$$
\Delta S = k_B \ln 2
$$

This was a monumental realization, anticipating Claude Shannon’s Information Theory by two decades. It established that information is physical. The “It” (entropy/energy) and the “Bit” (information/knowledge) were convertible currencies. Szilard’s engine showed that one could not talk about the “It” of the gas without accounting for the “Bit” in the observer’s memory process. This resolved the paradox: the entropy decrease in the gas is compensated by the entropy increase in the Demon’s memory process. This work lay dormant for decades but eventually led to Landauer’s Principle (1961), which confirmed that the erasure of information is the thermodynamic step that generates heat. In the context of the 1920s revolution, Szilard provided the mechanism for Bohr’s “uncontrollable interaction”: the observer is not a ghost; the observer is a thermodynamic engine entangled with the system.

---

### The Universal Machine: Hugh Everett III and the Relative State

By the 1950s, the “It” was in a fragile state: maintained as a probability wave by Schrödinger, fragmented into complementary contexts by Bohr, and tied to entropy by Szilard. Yet, the “Measurement Problem” remained: how does the probability wave ($\psi$) collapse into a single “It” (a specific record) upon observation? The standard Von Neumann formulation relied on an ad-hoc “Process 1” (collapse) that defied the Schrödinger equation (“Process 2”).

In 1957, Hugh Everett III, a graduate student of John Wheeler at Princeton, proposed a solution that required abandoning the last vestige of the classical “It”: the uniqueness of history. He took the Von Neumann formulation seriously but removed the collapse. He asked: What if the Schrödinger equation applies to everything, including the observer? He modeled the observer not as a metaphysical external agent (as Bohr effectively did by placing them on the classical side of the cut), but as a physical system, a mechanical automaton with a memory. He analyzed the interaction between a quantum system $S$ and an observer $O$.

Everett showed that if the observer interacts with a superposed system, the observer themselves enters a superposition. If the system is in state $\alpha |UP\rangle + \beta |DOWN\rangle$, the observer evolves into a state of: $\alpha |UP\rangle |“I saw UP”\rangle + \beta |DOWN\rangle |“I saw DOWN”\rangle$. There is no collapse. There is no single “It” that emerges. Instead, the reality is the correlation between the system and the memory. Everett called this the “Relative State” formulation. Relative to the memory state “I saw UP,” the electron is UP. Relative to “I saw DOWN,” it is DOWN. Both branches exist simultaneously in the universal wavefunction.

Everett was driven by the “Wigner’s Friend” paradox: if a friend observes a system, the friend sees a result. But to Wigner, standing outside the room, the friend is in a superposition until Wigner opens the door. Who is right? Everett answered: Both. The “It” is relative to the observer. While Bryce DeWitt later popularized this as the “Many Worlds Interpretation,” Everett’s original conception was closer to a pure information theory. He proved that a “typical” observer (defined by the measure of the Hilbert space coefficients) would record a sequence of results satisfying standard quantum statistics (the Born rule). Everett’s work represents the ultimate triumph of Information over Substance. Substance: There is no single, solid world. Information: The universal wave function is a purely information-theoretic entity, a catalog of all possible correlations.

This quantum revolution, with its dissolution of the independent “It” into informational potentia, measurement phenomena, entangled correlations, thermodynamic bits, and relative states, provided the philosophical and mathematical engine for Wheeler’s later “It from Bit” paradigm. The classical field’s continuity, already challenged by Einstein’s geometry, now faced an even more profound assault from the quantum domain, rendering the transition to geometrodynamics’ collapse not abrupt but inexorable, a culmination of the crisis that began with Heisenberg’s matrices and Bohr’s indivisible phenomena.

:::tip[Synopsis: The Quantum Dissolution of Substance 1925–1957]
Heisenberg’s matrices, Born’s probability rule, Bohr’s complementarity, Schrödinger’s entanglement, Szilard’s thermodynamic bit, and Everett’s relative states collectively annihilated the classical “It”: there remains only correlation, information, and observer-relative facts: no independent substance, no absolute trajectory.
:::